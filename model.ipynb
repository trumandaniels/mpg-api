{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is heavily based on this example:\n",
    "https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
    "\n",
    "\n",
    "With some light modifications using a different dataset and using a regression algorithim instead of classification\n",
    "\n",
    "This is really just a way for me to test webhosting a model on github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 13:56:34.598358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-08 13:56:34.598389: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = Path.cwd().joinpath(\"auto-mpg.csv\") #Edit if you change relative location of database\n",
    "dataframe = pd.read_csv(file_url, engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some quick cleanup of the dataframe:\n",
    "\n",
    "First making origin more readible, \n",
    "\n",
    "Then by converting horsepower into a numeric variable (it is automatically imported as a string type since ? is included in data). replacing null values formerly represented by ? in csv to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"origin\"].replace({1: \"American\", 2: \"European\", 3: \"Asian\"}, inplace=True)\n",
    "dataframe[\"horsepower\"] = pd.to_numeric(dataframe[\"horsepower\"], errors=\"coerce\") #sets \"?\" to NaN\n",
    "dataframe[\"horsepower\"].fillna(dataframe[\"horsepower\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>modelyear</th>\n",
       "      <th>origin</th>\n",
       "      <th>carname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  modelyear  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0         70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5         70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0         70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0         70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5         70   \n",
       "\n",
       "     origin                    carname  \n",
       "0  American  chevrolet chevelle malibu  \n",
       "1  American          buick skylark 320  \n",
       "2  American         plymouth satellite  \n",
       "3  American              amc rebel sst  \n",
       "4  American                ford torino  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 318 samples for training and 80 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 13:56:37.024749: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-08 13:56:37.024881: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-08 13:56:37.024959: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (KernelBlotto): /proc/driver/nvidia/version does not exist\n",
      "2022-01-08 13:56:37.025838: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"mpg\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'cylinders': <tf.Tensor: shape=(), dtype=int64, numpy=8>, 'displacement': <tf.Tensor: shape=(), dtype=float64, numpy=455.0>, 'horsepower': <tf.Tensor: shape=(), dtype=float64, numpy=225.0>, 'weight': <tf.Tensor: shape=(), dtype=int64, numpy=4951>, 'acceleration': <tf.Tensor: shape=(), dtype=float64, numpy=11.0>, 'modelyear': <tf.Tensor: shape=(), dtype=int64, numpy=73>, 'origin': <tf.Tensor: shape=(), dtype=string, numpy=b'American'>, 'carname': <tf.Tensor: shape=(), dtype=string, numpy=b'buick electra 225 custom'>}\n",
      "Target: tf.Tensor(12.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(8)\n",
    "val_ds = val_ds.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = keras.Input(shape=(1,), name=\"origin\", dtype=\"string\")\n",
    "\n",
    "\n",
    "# Numerical features\n",
    "cylinders = keras.Input(shape=(1,), name=\"cylinders\")\n",
    "displacement = keras.Input(shape=(1,), name=\"displacement\")\n",
    "horsepower = keras.Input(shape=(1,), name=\"horsepower\")\n",
    "weight = keras.Input(shape=(1,), name=\"weight\")\n",
    "modelyear = keras.Input(shape=(1,), name=\"modelyear\")\n",
    "acceleration = keras.Input(shape=(1,), name=\"acceleration\")\n",
    "\n",
    "all_inputs = [\n",
    "    cylinders,\n",
    "    displacement,\n",
    "    horsepower,\n",
    "    weight,\n",
    "    modelyear,\n",
    "    acceleration,\n",
    "    origin,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "#origin_encoded = encode_categorical_feature(origin, \"origin\", train_ds, False)\n",
    "origin_encoded = encode_categorical_feature(origin, \"origin\", train_ds, True)\n",
    "\n",
    "\n",
    "# Numerical features\n",
    "cylinders_encoded = encode_numerical_feature(cylinders, \"cylinders\", train_ds)\n",
    "displacement_encoded = encode_numerical_feature(displacement, \"displacement\", train_ds)\n",
    "horsepower_encoded = encode_numerical_feature(horsepower, \"horsepower\", train_ds)\n",
    "weight_encoded = encode_numerical_feature(weight, \"weight\", train_ds)\n",
    "modelyear_encoded = encode_numerical_feature(modelyear, \"modelyear\", train_ds)\n",
    "acceleration_encoded = encode_numerical_feature(acceleration, \"acceleration\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        cylinders_encoded,\n",
    "        displacement_encoded,\n",
    "        horsepower_encoded,\n",
    "        weight_encoded,\n",
    "        modelyear_encoded,\n",
    "        acceleration_encoded,\n",
    "        origin_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(7, activation=\"relu\")(all_features)\n",
    "x = layers.Dense(14)(x)\n",
    "x = layers.Dropout(0.05)(x)\n",
    "output = layers.Dense(1, activation=\"relu\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"mean_squared_error\", metrics=[\"mean_squared_error\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 1s 7ms/step - loss: 617.6617 - mean_squared_error: 617.6617 - val_loss: 554.8294 - val_mean_squared_error: 554.8294\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 600.2377 - mean_squared_error: 600.2377 - val_loss: 521.7151 - val_mean_squared_error: 521.7151\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 552.7647 - mean_squared_error: 552.7647 - val_loss: 454.9493 - val_mean_squared_error: 454.9493\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 480.0973 - mean_squared_error: 480.0973 - val_loss: 380.9146 - val_mean_squared_error: 380.9146\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 400.7905 - mean_squared_error: 400.7905 - val_loss: 300.1357 - val_mean_squared_error: 300.1357\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 312.8768 - mean_squared_error: 312.8768 - val_loss: 214.1328 - val_mean_squared_error: 214.1328\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 217.1380 - mean_squared_error: 217.1380 - val_loss: 131.4969 - val_mean_squared_error: 131.4969\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 123.6050 - mean_squared_error: 123.6050 - val_loss: 70.0806 - val_mean_squared_error: 70.0806\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 73.5326 - mean_squared_error: 73.5326 - val_loss: 41.2863 - val_mean_squared_error: 41.2863\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 47.5624 - mean_squared_error: 47.5624 - val_loss: 32.8522 - val_mean_squared_error: 32.8522\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 37.5742 - mean_squared_error: 37.5742 - val_loss: 27.7240 - val_mean_squared_error: 27.7240\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 33.7142 - mean_squared_error: 33.7142 - val_loss: 23.7638 - val_mean_squared_error: 23.7638\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 29.0183 - mean_squared_error: 29.0183 - val_loss: 20.6116 - val_mean_squared_error: 20.6116\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 25.8741 - mean_squared_error: 25.8741 - val_loss: 18.2177 - val_mean_squared_error: 18.2177\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 22.8313 - mean_squared_error: 22.8313 - val_loss: 16.4978 - val_mean_squared_error: 16.4978\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 20.8969 - mean_squared_error: 20.8969 - val_loss: 15.3088 - val_mean_squared_error: 15.3088\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 20.0223 - mean_squared_error: 20.0223 - val_loss: 14.1981 - val_mean_squared_error: 14.1981\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 17.6741 - mean_squared_error: 17.6741 - val_loss: 13.3931 - val_mean_squared_error: 13.3931\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 16.7570 - mean_squared_error: 16.7570 - val_loss: 12.6748 - val_mean_squared_error: 12.6748\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 16.2429 - mean_squared_error: 16.2429 - val_loss: 12.2105 - val_mean_squared_error: 12.2105\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 16.5219 - mean_squared_error: 16.5219 - val_loss: 11.6608 - val_mean_squared_error: 11.6608\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 14.8799 - mean_squared_error: 14.8799 - val_loss: 11.2133 - val_mean_squared_error: 11.2133\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 15.5448 - mean_squared_error: 15.5448 - val_loss: 10.9180 - val_mean_squared_error: 10.9180\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 15.9998 - mean_squared_error: 15.9998 - val_loss: 10.4775 - val_mean_squared_error: 10.4775\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.4465 - mean_squared_error: 13.4465 - val_loss: 10.1017 - val_mean_squared_error: 10.1017\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 14.9448 - mean_squared_error: 14.9448 - val_loss: 9.8167 - val_mean_squared_error: 9.8167\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 14.1660 - mean_squared_error: 14.1660 - val_loss: 9.5002 - val_mean_squared_error: 9.5002\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.3589 - mean_squared_error: 13.3589 - val_loss: 9.3068 - val_mean_squared_error: 9.3068\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.7281 - mean_squared_error: 12.7281 - val_loss: 9.0892 - val_mean_squared_error: 9.0892\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.3634 - mean_squared_error: 12.3634 - val_loss: 9.0193 - val_mean_squared_error: 9.0193\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.8694 - mean_squared_error: 12.8694 - val_loss: 8.7712 - val_mean_squared_error: 8.7712\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.4841 - mean_squared_error: 13.4841 - val_loss: 8.5692 - val_mean_squared_error: 8.5692\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.3431 - mean_squared_error: 12.3431 - val_loss: 8.5558 - val_mean_squared_error: 8.5558\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 10.9411 - mean_squared_error: 10.9411 - val_loss: 8.3845 - val_mean_squared_error: 8.3845\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.3878 - mean_squared_error: 13.3878 - val_loss: 8.2778 - val_mean_squared_error: 8.2778\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 11.3194 - mean_squared_error: 11.3194 - val_loss: 8.1706 - val_mean_squared_error: 8.1706\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.4836 - mean_squared_error: 12.4836 - val_loss: 8.0729 - val_mean_squared_error: 8.0729\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.4726 - mean_squared_error: 13.4726 - val_loss: 7.8390 - val_mean_squared_error: 7.8390\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.6148 - mean_squared_error: 12.6148 - val_loss: 7.7854 - val_mean_squared_error: 7.7854\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 11.1761 - mean_squared_error: 11.1761 - val_loss: 7.7919 - val_mean_squared_error: 7.7919\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 11.5437 - mean_squared_error: 11.5437 - val_loss: 7.5884 - val_mean_squared_error: 7.5884\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 11.2762 - mean_squared_error: 11.2762 - val_loss: 7.4458 - val_mean_squared_error: 7.4458\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 10.6010 - mean_squared_error: 10.6010 - val_loss: 7.3533 - val_mean_squared_error: 7.3533\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.3137 - mean_squared_error: 12.3137 - val_loss: 7.3012 - val_mean_squared_error: 7.3012\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 11.8526 - mean_squared_error: 11.8526 - val_loss: 7.2747 - val_mean_squared_error: 7.2747\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 11.3514 - mean_squared_error: 11.3514 - val_loss: 7.2144 - val_mean_squared_error: 7.2144\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 10.1882 - mean_squared_error: 10.1882 - val_loss: 7.2674 - val_mean_squared_error: 7.2674\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.0839 - mean_squared_error: 12.0839 - val_loss: 7.1901 - val_mean_squared_error: 7.1901\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 10.5113 - mean_squared_error: 10.5113 - val_loss: 7.0710 - val_mean_squared_error: 7.0710\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 10.8880 - mean_squared_error: 10.8880 - val_loss: 7.0355 - val_mean_squared_error: 7.0355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6855f20400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This car has gets an estimated 33.182308197021484 mpg\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"cylinders\":8,\n",
    "    \"displacement\":300,\n",
    "    \"horsepower\":150,\n",
    "    \"weight\":4500,\n",
    "    \"acceleration\":10,\n",
    "    \"modelyear\":96,\n",
    "    \"origin\":\"American\",    \n",
    "}\n",
    "\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(f\"This car has gets an estimated {predictions[0][0]} mpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/truman/Documents/DataAPI/mpg_model_saved/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = Path.cwd().joinpath(\"mpg_model_saved\")\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
