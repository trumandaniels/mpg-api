{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is heavily based on this example:\n",
    "https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
    "\n",
    "\n",
    "With some light modifications using a different dataset and using a regression algorithim instead of classification\n",
    "\n",
    "This is really just a way for me to test webhosting a model on github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 00:21:12.388791: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-08 00:21:12.388821: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"/home/truman/Documents/DataAPI/auto-mpg.csv\"\n",
    "dataframe = pd.read_csv(file_url, engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some quick cleanup of the dataframe:\n",
    "\n",
    "First making origin more readible, \n",
    "\n",
    "Then by converting horsepower into a numeric variable (it is automatically imported as a string type since ? is included in data). replacing null values formerly represented by ? in csv to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"origin\"].replace({1: \"American\", 2: \"European\", 3: \"Asian\"}, inplace=True)\n",
    "dataframe[\"horsepower\"] = pd.to_numeric(dataframe[\"horsepower\"], errors=\"coerce\") #sets \"?\" to NaN\n",
    "dataframe[\"horsepower\"].fillna(dataframe[\"horsepower\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>modelyear</th>\n",
       "      <th>origin</th>\n",
       "      <th>carname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>American</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  modelyear  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0         70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5         70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0         70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0         70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5         70   \n",
       "\n",
       "     origin                    carname  \n",
       "0  American  chevrolet chevelle malibu  \n",
       "1  American          buick skylark 320  \n",
       "2  American         plymouth satellite  \n",
       "3  American              amc rebel sst  \n",
       "4  American                ford torino  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 318 samples for training and 80 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 00:21:14.740284: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-08 00:21:14.740366: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-08 00:21:14.740408: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (KernelBlotto): /proc/driver/nvidia/version does not exist\n",
      "2022-01-08 00:21:14.740847: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"mpg\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'cylinders': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'displacement': <tf.Tensor: shape=(), dtype=float64, numpy=119.0>, 'horsepower': <tf.Tensor: shape=(), dtype=float64, numpy=97.0>, 'weight': <tf.Tensor: shape=(), dtype=int64, numpy=2545>, 'acceleration': <tf.Tensor: shape=(), dtype=float64, numpy=17.0>, 'modelyear': <tf.Tensor: shape=(), dtype=int64, numpy=75>, 'origin': <tf.Tensor: shape=(), dtype=string, numpy=b'Asian'>, 'carname': <tf.Tensor: shape=(), dtype=string, numpy=b'datsun 710'>}\n",
      "Target: tf.Tensor(24.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(8)\n",
    "val_ds = val_ds.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = keras.Input(shape=(1,), name=\"origin\", dtype=\"string\")\n",
    "\n",
    "\n",
    "# Numerical features\n",
    "cylinders = keras.Input(shape=(1,), name=\"cylinders\")\n",
    "displacement = keras.Input(shape=(1,), name=\"displacement\")\n",
    "horsepower = keras.Input(shape=(1,), name=\"horsepower\")\n",
    "weight = keras.Input(shape=(1,), name=\"weight\")\n",
    "modelyear = keras.Input(shape=(1,), name=\"modelyear\")\n",
    "acceleration = keras.Input(shape=(1,), name=\"acceleration\")\n",
    "\n",
    "all_inputs = [\n",
    "    cylinders,\n",
    "    displacement,\n",
    "    horsepower,\n",
    "    weight,\n",
    "    modelyear,\n",
    "    acceleration,\n",
    "    origin,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "#origin_encoded = encode_categorical_feature(origin, \"origin\", train_ds, False)\n",
    "origin_encoded = encode_categorical_feature(origin, \"origin\", train_ds, True)\n",
    "\n",
    "\n",
    "# Numerical features\n",
    "cylinders_encoded = encode_numerical_feature(cylinders, \"cylinders\", train_ds)\n",
    "displacement_encoded = encode_numerical_feature(displacement, \"displacement\", train_ds)\n",
    "horsepower_encoded = encode_numerical_feature(horsepower, \"horsepower\", train_ds)\n",
    "weight_encoded = encode_numerical_feature(weight, \"weight\", train_ds)\n",
    "modelyear_encoded = encode_numerical_feature(modelyear, \"modelyear\", train_ds)\n",
    "acceleration_encoded = encode_numerical_feature(acceleration, \"acceleration\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        cylinders_encoded,\n",
    "        displacement_encoded,\n",
    "        horsepower_encoded,\n",
    "        weight_encoded,\n",
    "        modelyear_encoded,\n",
    "        acceleration_encoded,\n",
    "        origin_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.15)(x)\n",
    "output = layers.Dense(1, activation=\"relu\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"mean_squared_error\", metrics=[\"mean_squared_error\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truman/dataenv/lib/python3.7/site-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['carname'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 7ms/step - loss: 607.2640 - mean_squared_error: 607.2640 - val_loss: 537.3174 - val_mean_squared_error: 537.3174\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 571.8925 - mean_squared_error: 571.8925 - val_loss: 497.6687 - val_mean_squared_error: 497.6687\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 522.3434 - mean_squared_error: 522.3434 - val_loss: 445.9981 - val_mean_squared_error: 445.9981\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 459.5651 - mean_squared_error: 459.5651 - val_loss: 386.2224 - val_mean_squared_error: 386.2224\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 391.7954 - mean_squared_error: 391.7954 - val_loss: 321.6194 - val_mean_squared_error: 321.6194\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 321.1454 - mean_squared_error: 321.1454 - val_loss: 256.7972 - val_mean_squared_error: 256.7972\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 249.7113 - mean_squared_error: 249.7113 - val_loss: 197.9821 - val_mean_squared_error: 197.9821\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 186.7745 - mean_squared_error: 186.7745 - val_loss: 145.2060 - val_mean_squared_error: 145.2060\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 132.6285 - mean_squared_error: 132.6285 - val_loss: 104.9185 - val_mean_squared_error: 104.9185\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 97.8434 - mean_squared_error: 97.8434 - val_loss: 74.9737 - val_mean_squared_error: 74.9737\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 67.9139 - mean_squared_error: 67.9139 - val_loss: 55.4415 - val_mean_squared_error: 55.4415\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 54.6607 - mean_squared_error: 54.6607 - val_loss: 42.9995 - val_mean_squared_error: 42.9995\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 44.2175 - mean_squared_error: 44.2175 - val_loss: 34.7481 - val_mean_squared_error: 34.7481\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 35.9682 - mean_squared_error: 35.9682 - val_loss: 30.0641 - val_mean_squared_error: 30.0641\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 33.1346 - mean_squared_error: 33.1346 - val_loss: 26.5135 - val_mean_squared_error: 26.5135\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 30.1672 - mean_squared_error: 30.1672 - val_loss: 24.1771 - val_mean_squared_error: 24.1771\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 28.7988 - mean_squared_error: 28.7988 - val_loss: 22.3511 - val_mean_squared_error: 22.3511\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 29.6769 - mean_squared_error: 29.6769 - val_loss: 20.9965 - val_mean_squared_error: 20.9965\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 28.0056 - mean_squared_error: 28.0056 - val_loss: 19.7515 - val_mean_squared_error: 19.7515\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 27.1825 - mean_squared_error: 27.1825 - val_loss: 18.7411 - val_mean_squared_error: 18.7411\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 24.5526 - mean_squared_error: 24.5526 - val_loss: 17.7208 - val_mean_squared_error: 17.7208\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 26.7502 - mean_squared_error: 26.7502 - val_loss: 16.8330 - val_mean_squared_error: 16.8330\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 26.0630 - mean_squared_error: 26.0630 - val_loss: 15.9293 - val_mean_squared_error: 15.9293\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 22.9615 - mean_squared_error: 22.9615 - val_loss: 15.2230 - val_mean_squared_error: 15.2230\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 22.8470 - mean_squared_error: 22.8470 - val_loss: 14.5678 - val_mean_squared_error: 14.5678\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 19.7782 - mean_squared_error: 19.7782 - val_loss: 13.7536 - val_mean_squared_error: 13.7536\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 20.9907 - mean_squared_error: 20.9907 - val_loss: 13.0986 - val_mean_squared_error: 13.0986\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 21.5613 - mean_squared_error: 21.5613 - val_loss: 12.3983 - val_mean_squared_error: 12.3983\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 20.2434 - mean_squared_error: 20.2434 - val_loss: 11.9130 - val_mean_squared_error: 11.9130\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 18.3427 - mean_squared_error: 18.3427 - val_loss: 11.5622 - val_mean_squared_error: 11.5622\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 19.9474 - mean_squared_error: 19.9474 - val_loss: 11.1106 - val_mean_squared_error: 11.1106\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 17.6039 - mean_squared_error: 17.6039 - val_loss: 10.7740 - val_mean_squared_error: 10.7740\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 18.1149 - mean_squared_error: 18.1149 - val_loss: 10.4082 - val_mean_squared_error: 10.4082\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 18.1175 - mean_squared_error: 18.1175 - val_loss: 10.1513 - val_mean_squared_error: 10.1513\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 18.1741 - mean_squared_error: 18.1741 - val_loss: 10.0658 - val_mean_squared_error: 10.0658\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 17.5644 - mean_squared_error: 17.5644 - val_loss: 9.6689 - val_mean_squared_error: 9.6689\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 14.6623 - mean_squared_error: 14.6623 - val_loss: 9.5153 - val_mean_squared_error: 9.5153\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 16.3208 - mean_squared_error: 16.3208 - val_loss: 9.4693 - val_mean_squared_error: 9.4693\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 17.9415 - mean_squared_error: 17.9415 - val_loss: 9.3806 - val_mean_squared_error: 9.3806\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 16.4472 - mean_squared_error: 16.4472 - val_loss: 8.9082 - val_mean_squared_error: 8.9082\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 16.5827 - mean_squared_error: 16.5827 - val_loss: 8.7406 - val_mean_squared_error: 8.7406\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 15.0471 - mean_squared_error: 15.0471 - val_loss: 8.7817 - val_mean_squared_error: 8.7817\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 15.3933 - mean_squared_error: 15.3933 - val_loss: 8.5987 - val_mean_squared_error: 8.5987\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 15.9045 - mean_squared_error: 15.9045 - val_loss: 8.5870 - val_mean_squared_error: 8.5870\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 15.7678 - mean_squared_error: 15.7678 - val_loss: 8.3623 - val_mean_squared_error: 8.3623\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 15.0138 - mean_squared_error: 15.0138 - val_loss: 8.1435 - val_mean_squared_error: 8.1435\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 14.3240 - mean_squared_error: 14.3240 - val_loss: 8.0440 - val_mean_squared_error: 8.0440\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.8010 - mean_squared_error: 13.8010 - val_loss: 8.0591 - val_mean_squared_error: 8.0591\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 14.6853 - mean_squared_error: 14.6853 - val_loss: 7.9439 - val_mean_squared_error: 7.9439\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.4006 - mean_squared_error: 13.4006 - val_loss: 8.0547 - val_mean_squared_error: 8.0547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72198195f8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This car has gets an estimated 28.225862503051758 mpg\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"cylinders\":8,\n",
    "    \"displacement\":300,\n",
    "    \"horsepower\":150,\n",
    "    \"weight\":4500,\n",
    "    \"acceleration\":10,\n",
    "    \"modelyear\":96,\n",
    "    \"origin\":\"American\",    \n",
    "}\n",
    "\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(f\"This car has gets an estimated {predictions[0][0]} mpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 00:21:50.299253: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/truman/Documents/DataAPI/mpg_model_saved/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/home/truman/Documents/DataAPI/mpg_model_saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
